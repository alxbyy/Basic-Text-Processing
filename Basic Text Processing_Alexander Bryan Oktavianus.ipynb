{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f7f4b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages (from pandas) (1.26.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: click in c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages (from scikit-learn) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Collecting numpy>=1.18.5\n",
      "  Using cached numpy-1.22.4-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "Requirement already satisfied: colorama in c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.1\n",
      "    Uninstalling numpy-1.26.1:\n",
      "      Successfully uninstalled numpy-1.26.1\n",
      "Successfully installed numpy-1.22.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -oogle-auth (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oogle-auth (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oogle-auth (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -oogle-auth (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution - (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oogle-auth (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.5.0 requires daal==2021.4.0, which is not installed.\n",
      "tensorflow-intel 2.14.0 requires numpy>=1.23.5, but you have numpy 1.22.4 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.22.4 which is incompatible.\n",
      "WARNING: Ignoring invalid distribution -oogle-auth (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oogle-auth (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oogle-auth (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\alexander bryan\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas nltk scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad2a48e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bd95869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case</td>\n",
       "      <td>Excellent value.</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence              Label    1  \\\n",
       "0  So there is no way for me to plug it in here i...                  0  NaN   \n",
       "1                                          Good case   Excellent value.    1   \n",
       "2                             Great for the jawbone.                  1  NaN   \n",
       "3  Tied to charger for conversations lasting more...                  0  NaN   \n",
       "4                                  The mic is great.                  1  NaN   \n",
       "\n",
       "     2    3   4  \n",
       "0  NaN  NaN NaN  \n",
       "1  NaN  NaN NaN  \n",
       "2  NaN  NaN NaN  \n",
       "3  NaN  NaN NaN  \n",
       "4  NaN  NaN NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_data = pd.read_csv('C:/Users/Alexander Bryan/sentiment labelled sentences/amazon_cells_labelled.csv', header=None, names=['Sentence', 'Label', '1', '2', '3', '4'], delimiter=None)\n",
    "amazon_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0cf1f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very</td>\n",
       "      <td>very</td>\n",
       "      <td>very slow-moving</td>\n",
       "      <td>aimless movie about a distressed</td>\n",
       "      <td>drifting young man.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>nearly half of whom walked out.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>the movie disappointed - became even more rid...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0                                             A very   \n",
       "1  Not sure who was more lost - the flat characte...   \n",
       "2  Attempting artiness with black & white and cle...   \n",
       "3       Very little music or anything to speak of.     \n",
       "4  The best scene in the movie was when Gerardo i...   \n",
       "\n",
       "                                               Label                  1  \\\n",
       "0                                               very   very slow-moving   \n",
       "1                  nearly half of whom walked out.                    0   \n",
       "2   the movie disappointed - became even more rid...                  0   \n",
       "3                                                  0                NaN   \n",
       "4                                                  1                NaN   \n",
       "\n",
       "                                   2                       3    4    5   6  \n",
       "0   aimless movie about a distressed   drifting young man.      0  NaN NaN  \n",
       "1                                NaN                     NaN  NaN  NaN NaN  \n",
       "2                                NaN                     NaN  NaN  NaN NaN  \n",
       "3                                NaN                     NaN  NaN  NaN NaN  \n",
       "4                                NaN                     NaN  NaN  NaN NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data = pd.read_csv('C:/Users/Alexander Bryan/sentiment labelled sentences/imdb_labelled.csv', header=None, names=['Sentence', 'Label', '1', '2', '3', '4', '5' , '6'], delimiter=None)\n",
    "imdb_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51f15e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Label    1    2    3   4\n",
       "0                           Wow... Loved this place.     1  NaN  NaN  NaN NaN\n",
       "1                                 Crust is not good.     0  NaN  NaN  NaN NaN\n",
       "2          Not tasty and the texture was just nasty.     0  NaN  NaN  NaN NaN\n",
       "3  Stopped by during the late May bank holiday of...     1  NaN  NaN  NaN NaN\n",
       "4  The selection on the menu was great and so wer...     1  NaN  NaN  NaN NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_data = pd.read_csv('C:/Users/Alexander Bryan/sentiment labelled sentences/yelp_labelled.csv', header=None, names=['Sentence', 'Label', '1', '2', '3', '4'], delimiter=None)\n",
    "yelp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "537d7685",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.DataFrame({\n",
    "    'Amazon': amazon_data.apply(lambda x: ' '.join([str(val) for val in x.dropna()]), axis=1),\n",
    "    'IMDB': imdb_data.apply(lambda x: ' '.join([str(val) for val in x.dropna()]), axis=1),\n",
    "    'Yelp': yelp_data.apply(lambda x: ' '.join([str(val) for val in x.dropna()]), axis=1)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0477679",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.columns = ['Amazon', 'IMDB', 'Yelp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05d032ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amazon</th>\n",
       "      <th>IMDB</th>\n",
       "      <th>Yelp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>A very  very  very slow-moving  aimless movie ...</td>\n",
       "      <td>Wow... Loved this place. 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case  Excellent value. 1</td>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>Crust is not good. 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone. 1</td>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>Not tasty and the texture was just nasty. 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>Very little music or anything to speak of.   0</td>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great. 1</td>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Amazon  \\\n",
       "0  So there is no way for me to plug it in here i...   \n",
       "1                      Good case  Excellent value. 1   \n",
       "2                           Great for the jawbone. 1   \n",
       "3  Tied to charger for conversations lasting more...   \n",
       "4                                The mic is great. 1   \n",
       "\n",
       "                                                IMDB  \\\n",
       "0  A very  very  very slow-moving  aimless movie ...   \n",
       "1  Not sure who was more lost - the flat characte...   \n",
       "2  Attempting artiness with black & white and cle...   \n",
       "3     Very little music or anything to speak of.   0   \n",
       "4  The best scene in the movie was when Gerardo i...   \n",
       "\n",
       "                                                Yelp  \n",
       "0                         Wow... Loved this place. 1  \n",
       "1                               Crust is not good. 0  \n",
       "2        Not tasty and the texture was just nasty. 0  \n",
       "3  Stopped by during the late May bank holiday of...  \n",
       "4  The selection on the menu was great and so wer...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "068484b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaned Amazon</th>\n",
       "      <th>Cleaned IMDB</th>\n",
       "      <th>Cleaned Yelp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so there is no way for me to plug it in here i...</td>\n",
       "      <td>a very very very aimless movie about a distres...</td>\n",
       "      <td>wow loved this place 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good case excellent value 1</td>\n",
       "      <td>not sure who was more lost the flat characters...</td>\n",
       "      <td>crust is not good 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great for the jawbone 1</td>\n",
       "      <td>attempting artiness with black white and cleve...</td>\n",
       "      <td>not tasty and the texture was just nasty 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tied to charger for conversations lasting more...</td>\n",
       "      <td>very little music or anything to speak of 0</td>\n",
       "      <td>stopped by during the late may bank holiday of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the mic is great 1</td>\n",
       "      <td>the best scene in the movie was when gerardo i...</td>\n",
       "      <td>the selection on the menu was great and so wer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Cleaned Amazon  \\\n",
       "0  so there is no way for me to plug it in here i...   \n",
       "1                        good case excellent value 1   \n",
       "2                            great for the jawbone 1   \n",
       "3  tied to charger for conversations lasting more...   \n",
       "4                                 the mic is great 1   \n",
       "\n",
       "                                        Cleaned IMDB  \\\n",
       "0  a very very very aimless movie about a distres...   \n",
       "1  not sure who was more lost the flat characters...   \n",
       "2  attempting artiness with black white and cleve...   \n",
       "3        very little music or anything to speak of 0   \n",
       "4  the best scene in the movie was when gerardo i...   \n",
       "\n",
       "                                        Cleaned Yelp  \n",
       "0                             wow loved this place 1  \n",
       "1                                crust is not good 0  \n",
       "2         not tasty and the texture was just nasty 0  \n",
       "3  stopped by during the late may bank holiday of...  \n",
       "4  the selection on the menu was great and so wer...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fungsi untuk membersihkan teks\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()  # Ubah teks menjadi lowercase\n",
    "        text = ' '.join([word for word in word_tokenize(text) if word.isalnum()])  # Hapus karakter non-alphanumeric\n",
    "        return text\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Menerapkan fungsi pada kolom 'Amazon', 'IMDB', dan 'Yelp'\n",
    "combined_data['Cleaned Amazon'] = combined_data['Amazon'].apply(clean_text)\n",
    "combined_data['Cleaned IMDB'] = combined_data['IMDB'].apply(clean_text)\n",
    "combined_data['Cleaned Yelp'] = combined_data['Yelp'].apply(clean_text)\n",
    "\n",
    "# Menggabungkan hasil pembersihan ke dalam kolom baru 'Cleaned Sentence'\n",
    "combined_data['Cleaned Sentence'] = combined_data['Cleaned Amazon'] + ' ' + combined_data['Cleaned IMDB'] + ' ' + combined_data['Cleaned Yelp']\n",
    "\n",
    "# Memilih kolom yang diperlukan\n",
    "combined_data_cleaned = combined_data[['Cleaned Amazon', 'Cleaned IMDB', 'Cleaned Yelp']]\n",
    "combined_data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4fa94d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokenized Amazon</th>\n",
       "      <th>Tokenized IMDB</th>\n",
       "      <th>Tokenized Yelp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[so, there, is, no, way, for, me, to, plug, it...</td>\n",
       "      <td>[a, very, very, very, aimless, movie, about, a...</td>\n",
       "      <td>[wow, loved, this, place, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[good, case, excellent, value, 1]</td>\n",
       "      <td>[not, sure, who, was, more, lost, the, flat, c...</td>\n",
       "      <td>[crust, is, not, good, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[great, for, the, jawbone, 1]</td>\n",
       "      <td>[attempting, artiness, with, black, white, and...</td>\n",
       "      <td>[not, tasty, and, the, texture, was, just, nas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[tied, to, charger, for, conversations, lastin...</td>\n",
       "      <td>[very, little, music, or, anything, to, speak,...</td>\n",
       "      <td>[stopped, by, during, the, late, may, bank, ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[the, mic, is, great, 1]</td>\n",
       "      <td>[the, best, scene, in, the, movie, was, when, ...</td>\n",
       "      <td>[the, selection, on, the, menu, was, great, an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Tokenized Amazon  \\\n",
       "0  [so, there, is, no, way, for, me, to, plug, it...   \n",
       "1                  [good, case, excellent, value, 1]   \n",
       "2                      [great, for, the, jawbone, 1]   \n",
       "3  [tied, to, charger, for, conversations, lastin...   \n",
       "4                           [the, mic, is, great, 1]   \n",
       "\n",
       "                                      Tokenized IMDB  \\\n",
       "0  [a, very, very, very, aimless, movie, about, a...   \n",
       "1  [not, sure, who, was, more, lost, the, flat, c...   \n",
       "2  [attempting, artiness, with, black, white, and...   \n",
       "3  [very, little, music, or, anything, to, speak,...   \n",
       "4  [the, best, scene, in, the, movie, was, when, ...   \n",
       "\n",
       "                                      Tokenized Yelp  \n",
       "0                       [wow, loved, this, place, 1]  \n",
       "1                          [crust, is, not, good, 0]  \n",
       "2  [not, tasty, and, the, texture, was, just, nas...  \n",
       "3  [stopped, by, during, the, late, may, bank, ho...  \n",
       "4  [the, selection, on, the, menu, was, great, an...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fungsi untuk tokenisasi\n",
    "def tokenize_text(text):\n",
    "    if isinstance(text, str):\n",
    "        tokens = word_tokenize(text)\n",
    "        return tokens\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Menerapkan fungsi pada kolom 'Amazon', 'IMDB', dan 'Yelp'\n",
    "combined_data['Tokenized Amazon'] = combined_data['Cleaned Amazon'].apply(tokenize_text)\n",
    "combined_data['Tokenized IMDB'] = combined_data['Cleaned IMDB'].apply(tokenize_text)\n",
    "combined_data['Tokenized Yelp'] = combined_data['Cleaned Yelp'].apply(tokenize_text)\n",
    "\n",
    "# Menggabungkan hasil tokenisasi ke dalam kolom baru 'Tokenized Sentence'\n",
    "combined_data['Tokenized Sentence'] = combined_data.apply(lambda row: ' '.join(row['Tokenized Amazon'] + row['Tokenized IMDB'] + row['Tokenized Yelp']), axis=1)\n",
    "\n",
    "# Memilih kolom yang diperlukan\n",
    "combined_data_tokenized = combined_data[['Tokenized Amazon', 'Tokenized IMDB', 'Tokenized Yelp']]\n",
    "combined_data_tokenized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b1047cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stemmed Amazon</th>\n",
       "      <th>Stemmed IMDB</th>\n",
       "      <th>Stemmed Yelp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[so, there, is, no, way, for, me, to, plug, it...</td>\n",
       "      <td>[a, veri, veri, veri, aimless, movi, about, a,...</td>\n",
       "      <td>[wow, love, thi, place, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[good, case, excel, valu, 1]</td>\n",
       "      <td>[not, sure, who, wa, more, lost, the, flat, ch...</td>\n",
       "      <td>[crust, is, not, good, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[great, for, the, jawbon, 1]</td>\n",
       "      <td>[attempt, arti, with, black, white, and, cleve...</td>\n",
       "      <td>[not, tasti, and, the, textur, wa, just, nasti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[tie, to, charger, for, convers, last, more, t...</td>\n",
       "      <td>[veri, littl, music, or, anyth, to, speak, of, 0]</td>\n",
       "      <td>[stop, by, dure, the, late, may, bank, holiday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[the, mic, is, great, 1]</td>\n",
       "      <td>[the, best, scene, in, the, movi, wa, when, ge...</td>\n",
       "      <td>[the, select, on, the, menu, wa, great, and, s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Stemmed Amazon  \\\n",
       "0  [so, there, is, no, way, for, me, to, plug, it...   \n",
       "1                       [good, case, excel, valu, 1]   \n",
       "2                       [great, for, the, jawbon, 1]   \n",
       "3  [tie, to, charger, for, convers, last, more, t...   \n",
       "4                           [the, mic, is, great, 1]   \n",
       "\n",
       "                                        Stemmed IMDB  \\\n",
       "0  [a, veri, veri, veri, aimless, movi, about, a,...   \n",
       "1  [not, sure, who, wa, more, lost, the, flat, ch...   \n",
       "2  [attempt, arti, with, black, white, and, cleve...   \n",
       "3  [veri, littl, music, or, anyth, to, speak, of, 0]   \n",
       "4  [the, best, scene, in, the, movi, wa, when, ge...   \n",
       "\n",
       "                                        Stemmed Yelp  \n",
       "0                         [wow, love, thi, place, 1]  \n",
       "1                          [crust, is, not, good, 0]  \n",
       "2  [not, tasti, and, the, textur, wa, just, nasti...  \n",
       "3  [stop, by, dure, the, late, may, bank, holiday...  \n",
       "4  [the, select, on, the, menu, wa, great, and, s...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Membuat sebuah instance dari Porter stemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# Fungsi untuk stemming\n",
    "def stem_text(tokens):\n",
    "    return [porter.stem(token) for token in tokens]\n",
    "\n",
    "# Menerapkan fungsi pada kolom 'Amazon', 'IMDB', dan 'Yelp'\n",
    "combined_data['Stemmed Amazon'] = combined_data['Tokenized Amazon'].apply(stem_text)\n",
    "combined_data['Stemmed IMDB'] = combined_data['Tokenized IMDB'].apply(stem_text)\n",
    "combined_data['Stemmed Yelp'] = combined_data['Tokenized Yelp'].apply(stem_text)\n",
    "\n",
    "# Menggabungkan hasil stemming ke dalam kolom baru 'Stemmed Sentence'\n",
    "combined_data['Stemmed Sentence'] = combined_data.apply(lambda row: ' '.join(row['Stemmed Amazon'] + row['Stemmed IMDB'] + row['Stemmed Yelp']), axis=1)\n",
    "\n",
    "# Memilih kolom yang diperlukan\n",
    "combined_data_stemmed = combined_data[['Stemmed Amazon', 'Stemmed IMDB', 'Stemmed Yelp']]\n",
    "combined_data_stemmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4aeaaa92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filtered Amazon</th>\n",
       "      <th>Filtered IMDB</th>\n",
       "      <th>Filtered Yelp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[way, plug, us, unless, go, convert, 0]</td>\n",
       "      <td>[veri, veri, veri, aimless, movi, distress, dr...</td>\n",
       "      <td>[wow, love, thi, place, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[good, case, excel, valu, 1]</td>\n",
       "      <td>[sure, wa, lost, flat, charact, audienc, nearl...</td>\n",
       "      <td>[crust, good, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[great, jawbon, 1]</td>\n",
       "      <td>[attempt, arti, black, white, clever, camera, ...</td>\n",
       "      <td>[tasti, textur, wa, nasti, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[tie, charger, convers, last, 45, problem, 0]</td>\n",
       "      <td>[veri, littl, music, anyth, speak, 0]</td>\n",
       "      <td>[stop, dure, late, may, bank, holiday, rick, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[mic, great, 1]</td>\n",
       "      <td>[best, scene, movi, wa, gerardo, tri, find, so...</td>\n",
       "      <td>[select, menu, wa, great, price, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Filtered Amazon  \\\n",
       "0        [way, plug, us, unless, go, convert, 0]   \n",
       "1                   [good, case, excel, valu, 1]   \n",
       "2                             [great, jawbon, 1]   \n",
       "3  [tie, charger, convers, last, 45, problem, 0]   \n",
       "4                                [mic, great, 1]   \n",
       "\n",
       "                                       Filtered IMDB  \\\n",
       "0  [veri, veri, veri, aimless, movi, distress, dr...   \n",
       "1  [sure, wa, lost, flat, charact, audienc, nearl...   \n",
       "2  [attempt, arti, black, white, clever, camera, ...   \n",
       "3              [veri, littl, music, anyth, speak, 0]   \n",
       "4  [best, scene, movi, wa, gerardo, tri, find, so...   \n",
       "\n",
       "                                       Filtered Yelp  \n",
       "0                         [wow, love, thi, place, 1]  \n",
       "1                                   [crust, good, 0]  \n",
       "2                      [tasti, textur, wa, nasti, 0]  \n",
       "3  [stop, dure, late, may, bank, holiday, rick, s...  \n",
       "4                [select, menu, wa, great, price, 1]  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fungsi untuk filtering stop words\n",
    "def filter_stop_words(tokens):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return [token for token in tokens if token not in stop_words]\n",
    "\n",
    "# Menerapkan fungsi pada kolom 'Amazon', 'IMDB', dan 'Yelp'\n",
    "combined_data['Filtered Amazon'] = combined_data['Stemmed Amazon'].apply(filter_stop_words)\n",
    "combined_data['Filtered IMDB'] = combined_data['Stemmed IMDB'].apply(filter_stop_words)\n",
    "combined_data['Filtered Yelp'] = combined_data['Stemmed Yelp'].apply(filter_stop_words)\n",
    "\n",
    "# Menggabungkan hasil filtering ke dalam kolom baru 'Filtered Sentence'\n",
    "combined_data['Filtered Sentence'] = combined_data.apply(lambda row: ' '.join(row['Filtered Amazon'] + row['Filtered IMDB'] + row['Filtered Yelp']), axis=1)\n",
    "\n",
    "# Memilih kolom yang diperlukan\n",
    "combined_data_filtered = combined_data[['Filtered Amazon', 'Filtered IMDB', 'Filtered Yelp']]\n",
    "combined_data_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "df66cc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral     813\n",
      "Positive    159\n",
      "Negative     28\n",
      "Name: Sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Membuat fungsi untuk memberikan label sentimen\n",
    "def label_sentiment(text):\n",
    "    # Misalnya, kita akan anggap sentimen positif jika terdapat kata 'good' dan sentimen negatif jika terdapat kata 'bad'\n",
    "    if 'good' in text:\n",
    "        return 'Positive'\n",
    "    elif 'bad' in text:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Menerapkan fungsi pada kolom 'Filtered Sentence' untuk memberikan label sentimen\n",
    "combined_data['Sentiment'] = combined_data['Filtered Sentence'].apply(label_sentiment)\n",
    "\n",
    "# Menampilkan hasil analisis sentimen\n",
    "sentiment_counts = combined_data['Sentiment'].value_counts()\n",
    "print(sentiment_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d44ee71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "286b8948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membagi data menjadi data latih dan data uji\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(combined_data['Filtered Sentence'], combined_data['Sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc5bf657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggunakan CountVectorizer untuk mengonversi teks menjadi vektor fitur\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_data)\n",
    "X_test = vectorizer.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0955f6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Membuat dan melatih model Naive Bayes\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f7fd3362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menguji model pada data uji\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0561625a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.875\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      0.14      0.25         7\n",
      "     Neutral       0.88      0.99      0.93       152\n",
      "    Positive       0.86      0.59      0.70        41\n",
      "\n",
      "    accuracy                           0.88       200\n",
      "   macro avg       0.91      0.57      0.62       200\n",
      "weighted avg       0.88      0.88      0.86       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi performa model\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "report = classification_report(test_labels, predictions)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:\\n', report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b36a557",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.to_csv(\"C:/Users/Alexander Bryan/sentiment labelled sentences/combined_processed_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
